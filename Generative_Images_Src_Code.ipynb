{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarunHarish98/ComputerVision/blob/main/Generative_Images_Src_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Varun Hosadurga Harish**"
      ],
      "metadata": {
        "id": "aFuixQns6-eB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "TensorFLow Hub module based on a Generative Adversarial Network (GAN). It maps N-dimensional vectors, called latent space, to RGB images\n",
        "\n",
        "Two examples are considered:\n",
        "* **Mapping** from latent space to images, and\n",
        "* Given a target image, **using gradient descent to find** a latent vector that generates an image similar to the target image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KNM3kA0arrUu",
        "outputId": "a677f318-9b8d-49b9-a138-cb1425adca0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-xzhy8p3z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-xzhy8p3z\n",
            "  Resolved https://github.com/tensorflow/docs to commit ec765851b8312bdc4dcf685e41020ce568c7bff2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2023.10.27.81990) (2.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (0.13.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2023.10.27.81990) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "# Install imageio for creating animations.\n",
        "# Installing packages required for the program\n",
        "# imageio, scikit-image are two packages required\n",
        "!pip -q install imageio\n",
        "!pip -q install scikit-image\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "#@title Imports and function definitions\n",
        "from absl import logging\n",
        "\n",
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "from IPython import display\n",
        "from skimage import transform\n",
        "\n",
        "# Representing the dimensionality of the latent space\n",
        "latent_dim = 512\n",
        "\n",
        "# Interpolation - process of adding frames in between key frames\n",
        "# Involves normalisation, First normalizes v2 to same norm as v1\n",
        "# further interpolate between the two vectors on the sphere of higher dimensions\n",
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)\n",
        "\n",
        "# Display the image\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "# For a set of images combine them and create an animation in gif format.\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "# Make sure the error level is disabled for unncessary logging\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "## Latent space interpolation\n",
        "# Interpolation of Latent Space\n",
        "# It contains a pre trained data set required for Progressive Generative Adversarial Network (GAN)\n",
        "progan = hub.load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']\n",
        "# Generate 2 random vectors for interpolation\n",
        "def interpolate_between_vectors():\n",
        "  v1 = tf.random.normal([latent_dim])\n",
        "  v2 = tf.random.normal([latent_dim])\n",
        "\n",
        "  # Creating a tensor for 50 steps of interpolation between v1 and v2\n",
        "  vectors = interpolate_hypersphere(v1, v2, 50)\n",
        "\n",
        "  # Using the pretrained data for Pregressive GAN to generate images from interpolated vectors\n",
        "  interpolated_images = progan(vectors)['default']\n",
        "\n",
        "  return interpolated_images\n",
        "\n",
        "interpolated_images = interpolate_between_vectors()\n",
        "# Animate the result\n",
        "animate(interpolated_images)\n",
        "# Fix a target image. As an example use an image generated from the module\n",
        "# If we want to upload our own image,\n",
        "# set image_from_module_space as False\n",
        "image_from_module_space = True  # @param { isTemplate:true, type:\"boolean\" }\n",
        "# Get a random image from the latent space\n",
        "def get_module_space_image():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  images = progan(vector)['default'][0]\n",
        "  return images\n",
        "# If uploading image on own, this method is used\n",
        "def upload_image():\n",
        "  uploaded = files.upload()\n",
        "  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
        "  return transform.resize(image, [128, 128])\n",
        "# Choose the target image\n",
        "if image_from_module_space:\n",
        "  target_image = get_module_space_image()\n",
        "else:\n",
        "  target_image = upload_image()\n",
        "# Display the image\n",
        "display_image(target_image)\n",
        "# Now define after defining loss function between target and image generated by latent space, minimize the loss\n",
        "# using gradient descient algorithm\n",
        "# Gradient Descent Algorithm\n",
        "#   - If the derivative/gradient is decreasing then move in same direction\n",
        "#   - else, move in opposite direction\n",
        "tf.random.set_seed(42)\n",
        "initial_vector = tf.random.normal([1, latent_dim])\n",
        "# Display the image\n",
        "display_image(progan(initial_vector)['default'][0])\n",
        "def find_closest_latent_vector(initial_vector, num_optimization_steps,\n",
        "                               steps_per_image):\n",
        "  images = []\n",
        "  losses = []\n",
        "\n",
        "  vector = tf.Variable(initial_vector)\n",
        "  # Using Adam's optimizer for easy computation steps, learning rate - a hyper parameters\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "  # Mean Absolute Error function\n",
        "  loss_fn = tf.losses.MeanAbsoluteError(reduction=\"sum\")\n",
        "\n",
        "  for step in range(num_optimization_steps):\n",
        "    # For better readability\n",
        "    if (step % 100)==0:\n",
        "      print()\n",
        "    print('.', end='')\n",
        "    # GradientTape to record operations for automatic differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "      image = progan(vector.read_value())['default'][0]\n",
        "      # If current step is equal to steps_per_image then store the image\n",
        "      if (step % steps_per_image) == 0:\n",
        "        images.append(image.numpy())\n",
        "      # CAlculate the mean absolute error for the target image\n",
        "      target_image_difference = loss_fn(image, target_image[:,:,:3])\n",
        "      # The latent vectors were sampled from a normal distribution. We can get\n",
        "      # more realistic images if we regularize the length of the latent vector to\n",
        "      # the average length of vector from this distribution.\n",
        "      # Regularisation of the vector\n",
        "      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
        "\n",
        "      loss = target_image_difference + regularizer\n",
        "      losses.append(loss.numpy())\n",
        "    # Get the gradients of the loss with respect to the latent vector.\n",
        "    grads = tape.gradient(loss, [vector])\n",
        "    optimizer.apply_gradients(zip(grads, [vector]))\n",
        "\n",
        "  return images, losses\n",
        "\n",
        "\n",
        "num_optimization_steps=200\n",
        "steps_per_image=5\n",
        "images, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)\n",
        "# Plot the loss\n",
        "plt.plot(loss)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "animate(np.stack(images))\n",
        "# **Comparing** the result to the target:\n",
        "# Displays the last generated image alongside the target image for visual comparison\n",
        "display_image(np.concatenate([images[-1], target_image], axis=1))\n",
        "# If image is from the module space, the descent is quick and converges to a reasonable sample.  The descent will only converge if the image is reasonably close to the space of training images.\n",
        "\n",
        "# Further ways to descend faster and create a realistic image\n",
        "# * Initializing from a random vector in multiple runs\n",
        "# * Using different loss (quadratic) on the image difference.\n",
        "# * Using different regularizer on the latent vector.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "N6ZDpd9XzFeN"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}